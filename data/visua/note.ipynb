{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 21, 6])\n",
      "torch.Size([1, 4, 17, 4])\n",
      "1\n",
      "torch.Size([1, 272])\n",
      "torch.Size([1, 4, 17, 4])\n",
      "torch.Size([1, 8, 21, 6])\n",
      "torch.Size([1, 1, 25, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "x = torch.rand((1,1,25,8))\n",
    "conv1 = nn.Conv2d(1, 8, (5, 3), bias=False)\n",
    "conv2 = nn.Conv2d(8, 4, (5, 3), bias=False)\n",
    "#conv3 = nn.Conv2d(16, 32, (5, 3), bias=False)\n",
    "fc1 = nn.Linear(4 * 17 * 4, 32, bias=False)\n",
    "fc2 = nn.Linear(32, 4 * 17 *4, bias=False) \n",
    "#deconv1 = nn.ConvTranspose2d(32, 16, (5, 3), bias=False)\n",
    "deconv2 = nn.ConvTranspose2d(4, 8, (5, 3), bias=False)\n",
    "deconv3 = nn.ConvTranspose2d(8, 1, (5, 3), bias=False)\n",
    "bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "bn3 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "bn4 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "bn5 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "\n",
    "\n",
    "x = conv1(x)\n",
    "x = F.leaky_relu(bn1(x))\n",
    "print(x.shape)\n",
    "x = conv2(x)\n",
    "x = F.leaky_relu(bn2(x))\n",
    "print(x.shape)\n",
    "print(x.size(0))\n",
    "x = x.view(x.size(0), -1)\n",
    "x = fc1(x)\n",
    "#x = conv3(x)\n",
    "#x = F.leaky_relu(bn3(x))\n",
    "#print(x.shape)\n",
    "#x = deconv1(x)\n",
    "#x = F.leaky_relu(bn4(x))\n",
    "#print(x.shape)\n",
    "x = fc2(x)\n",
    "print(x.shape)\n",
    "x = x.view(x.size(0), 4, 17, 4)\n",
    "print(x.shape)\n",
    "x = deconv2(x)\n",
    "x = F.leaky_relu(bn3(x))\n",
    "print(x.shape)\n",
    "x = deconv3(x)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 200])\n",
      "torch.Size([1, 200])\n",
      "torch.Size([1, 1, 25, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "x = torch.rand((1,1,25,8))\n",
    "\n",
    "r = nn.ReLU()\n",
    "l1 = nn.Linear(25 * 8, 64)\n",
    "l2 = nn.Linear(64, 32)\n",
    "l3 = nn.Linear(32, 64)\n",
    "l4 = nn.Linear(64, 25 * 8)\n",
    "\n",
    "x = x.view(x.size(0), -1)\n",
    "print(x.shape)\n",
    "x = l1(x)\n",
    "print(x.shape)\n",
    "x = r(x)\n",
    "print(x.shape)\n",
    "x = l2(x)\n",
    "print(x.shape)\n",
    "x = r(x)\n",
    "print(x.shape)\n",
    "x = l3(x)\n",
    "print(x.shape)\n",
    "x = r(x)\n",
    "print(x.shape)\n",
    "x = l4(x)\n",
    "print(x.shape)\n",
    "x = r(x)\n",
    "print(x.shape)\n",
    "x = x.view(x.size(0), 1, 25, 8)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5583988, 25, 3)\n",
      "(25, 3)\n",
      "[0.4444558  0.05479737 3.57294   ]\n",
      "[0. 0. 0.]\n",
      "[-1.6270000e-04  2.9607103e-01 -2.4220000e-03]\n",
      "[-0.0024191   0.58584423 -0.017996  ]\n",
      "[ 0.0236965   0.70612743 -0.011611  ]\n",
      "[-0.1027518   0.46246813 -0.133952  ]\n",
      "[-0.1710374   0.21617593 -0.180318  ]\n",
      "[-0.181603    0.00223845 -0.230559  ]\n",
      "[-0.184845   -0.03776962 -0.234286  ]\n",
      "[0.101496   0.46086843 0.022315  ]\n",
      "[0.1288878  0.21128823 0.05692   ]\n",
      "[ 0.1311071  -0.02850716  0.061787  ]\n",
      "[ 0.1226211  -0.07609518  0.077901  ]\n",
      "[-0.0499064   0.00275837 -0.068529  ]\n",
      "[-0.1114496  -0.29816257 -0.090842  ]\n",
      "[-0.1421379  -0.62512567 -0.046491  ]\n",
      "[-0.1183107  -0.67890907 -0.076339  ]\n",
      "[ 0.0408244 -0.0045337 -0.003349 ]\n",
      "[-0.0086999  -0.29745537  0.004447  ]\n",
      "[-0.0638813  -0.61934737  0.043875  ]\n",
      "[-0.0393935  -0.67289387  0.00871   ]\n",
      "[-0.0015455   0.51429853 -0.011772  ]\n",
      "[-0.1870992  -0.09917225 -0.233152  ]\n",
      "[-0.1545815  -0.05198419 -0.220384  ]\n",
      "[ 0.1170352  -0.13266193  0.099379  ]\n",
      "[ 0.1032143  -0.09199058  0.04886   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_data = np.load('/home/vimlab/workspace/source/PyTorch-Deep-SVDD/data/NTU/ntu_skeleton_feature.npy')\n",
    "my_data = my_data[:,:,0:3]\n",
    "print(my_data.shape)\n",
    "print(my_data[0].shape)\n",
    "#print(my_data[0])\n",
    "\n",
    "moving_point = my_data[1][0]\n",
    "print(moving_point)\n",
    "for i in range(25):\n",
    "    print(my_data[1][i]-moving_point)\n",
    "\n",
    "\n",
    "# def normalize_joint_coordinates(data):\n",
    "\n",
    "#     n, j, _ = data.shape\n",
    "#     for i in range(n):\n",
    "#         moving_point = data[0]\n",
    "#         for k in range(j):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5583988, 25, 3)\n",
      "(25, 3)\n",
      "[0.4442474 0.054712  3.57226  ]\n",
      "[0. 0. 0.]\n",
      "[-0.0028485  0.2957536 -0.006999 ]\n",
      "[-0.0099842  0.5848849 -0.030055 ]\n",
      "[ 0.0234223  0.7058644 -0.014124 ]\n",
      "[-0.1054737  0.4631597 -0.137984 ]\n",
      "[-0.1722978  0.2161725 -0.18178  ]\n",
      "[-0.1795962   0.00458567 -0.232241  ]\n",
      "[-0.1690526  -0.04177333 -0.225016  ]\n",
      "[0.0940839 0.4590389 0.010354 ]\n",
      "[0.1215388 0.2094954 0.045097 ]\n",
      "[ 0.1210065  -0.02941541  0.051527  ]\n",
      "[ 0.1184367  -0.07142435  0.070447  ]\n",
      "[-0.0498677   0.00286404 -0.06818   ]\n",
      "[-0.1169443 -0.2978638 -0.088864 ]\n",
      "[-0.1416032 -0.6247373 -0.044441 ]\n",
      "[-0.1182599 -0.6788275 -0.075572 ]\n",
      "[ 0.040842   -0.00458837 -0.003689  ]\n",
      "[-0.0097486 -0.2980684  0.004469 ]\n",
      "[-0.0635423 -0.6190805  0.044873 ]\n",
      "[-0.0387976 -0.6738308  0.011662 ]\n",
      "[-0.0077229  0.5135517 -0.021756 ]\n",
      "[-0.1768409  -0.10610767 -0.220892  ]\n",
      "[-0.1199589  -0.04929545 -0.21441   ]\n",
      "[ 0.1079957 -0.1258486  0.093002 ]\n",
      "[ 0.1024718  -0.08883885  0.044558  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_data = np.load('/home/vimlab/workspace/source/PyTorch-Deep-SVDD/data/NTU/ntu_skeleton_feature.npy')\n",
    "my_data = my_data[:,:,0:3]\n",
    "print(my_data.shape)\n",
    "print(my_data[0].shape)\n",
    "#print(my_data[0])\n",
    "\n",
    "moving_point = my_data[1][0]\n",
    "print(moving_point)\n",
    "for i in range(25):\n",
    "    print(my_data[1][i]-moving_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5583988, 25, 3)\n",
      "(25, 3)\n",
      "[[ 4.444558e-01  5.479737e-02  3.572940e+00]\n",
      " [ 4.442931e-01  3.508684e-01  3.570518e+00]\n",
      " [ 4.420367e-01  6.406416e-01  3.554944e+00]\n",
      " [ 4.681523e-01  7.609248e-01  3.561329e+00]\n",
      " [ 3.417040e-01  5.172655e-01  3.438988e+00]\n",
      " [ 2.734184e-01  2.709733e-01  3.392622e+00]\n",
      " [ 2.628528e-01  5.703582e-02  3.342381e+00]\n",
      " [ 2.596108e-01  1.702775e-02  3.338654e+00]\n",
      " [ 5.459518e-01  5.156658e-01  3.595255e+00]\n",
      " [ 5.733436e-01  2.660856e-01  3.629860e+00]\n",
      " [ 5.755629e-01  2.629021e-02  3.634727e+00]\n",
      " [ 5.670769e-01 -2.129781e-02  3.650841e+00]\n",
      " [ 3.945494e-01  5.755574e-02  3.504411e+00]\n",
      " [ 3.330062e-01 -2.433652e-01  3.482098e+00]\n",
      " [ 3.023179e-01 -5.703283e-01  3.526449e+00]\n",
      " [ 3.261451e-01 -6.241117e-01  3.496601e+00]\n",
      " [ 4.852802e-01  5.026367e-02  3.569591e+00]\n",
      " [ 4.357559e-01 -2.426580e-01  3.577387e+00]\n",
      " [ 3.805745e-01 -5.645500e-01  3.616815e+00]\n",
      " [ 4.050623e-01 -6.180965e-01  3.581650e+00]\n",
      " [ 4.429103e-01  5.690959e-01  3.561168e+00]\n",
      " [ 2.573566e-01 -4.437488e-02  3.339788e+00]\n",
      " [ 2.898743e-01  2.813176e-03  3.352556e+00]\n",
      " [ 5.614910e-01 -7.786456e-02  3.672319e+00]\n",
      " [ 5.476701e-01 -3.719321e-02  3.621800e+00]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_data = np.load('/home/vimlab/workspace/source/PyTorch-Deep-SVDD/data/NTU/ntu_skeleton_feature.npy')\n",
    "my_data = my_data[:,:,0:3]\n",
    "print(my_data.shape)\n",
    "print(my_data[0].shape)\n",
    "print(my_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
      "        5.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3,4,5,6,7,8,9,10],[10,9,8,7,6,5,4,3,2,1]])\n",
    "print(torch.mean(a, dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skel_convautoencoder(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (deconv1): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (deconv2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn4): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (deconv3): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class skel_convautoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(skel_convautoencoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "\n",
    "        # self.fc1 = nn.Linear(4 * 17 * 4, 32, bias=False)\n",
    "        # self.fc2 = nn.Linear(32, 4 * 17 *4, bias=False) \n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, 3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(16, eps=1e-04, affine=False)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, 8, 3, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(8, 1, 3, bias=False)\n",
    "\n",
    "model = skel_convautoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = torch.zeros(6)\n",
    "a[:3] = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006065683842671319\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "my_data = np.load('/home/vimlab/workspace/source/PyTorch-Deep-SVDD_real/data/NTU/Our_ntu_skeleton_data_with_synthetic.npz')\n",
    "\n",
    "train = my_data['train']\n",
    "test = my_data['test']\n",
    "\n",
    "x = train[:,:,0]\n",
    "print(x.flatten().mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [1 1 1]\n",
      "  [2 2 2]]\n",
      "\n",
      " [[3 3 3]\n",
      "  [4 4 4]\n",
      "  [5 5 5]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(6)\n",
    "b = np.arange(6)\n",
    "c = np.arange(6)\n",
    "\n",
    "d = [[0, 1, 2], [3, 4, 5]]\n",
    "\n",
    "a = a.reshape(-1,3,1)\n",
    "b = b.reshape(-1,3,1)\n",
    "c = c.reshape(-1,3,1)\n",
    "\n",
    "\n",
    "print(np.concatenate([a, b, c], axis=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56578/56578 [00:00<00:00, 2797686.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4030455, 75)\n",
      "(742115, 150)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "with open('/home/vimlab/workspace/source/PyTorch-Deep-SVDD_real/data/NTU/raw_denoised_joints.pkl', 'rb') as fr:\n",
    "    raw_skes_data = pickle.load(fr)\n",
    "\n",
    "one_denoised_poses_list = []\n",
    "two_denoised_poses_list = []\n",
    "\n",
    "for (idx, body_data) in enumerate(tqdm(raw_skes_data)):\n",
    "    if body_data.shape[1]==75:\n",
    "        one_denoised_poses_list.append(body_data)\n",
    "    elif body_data.shape[1]==150:\n",
    "        two_denoised_poses_list.append(body_data)\n",
    "\n",
    "one_denoised_poses = np.concatenate(one_denoised_poses_list, axis=0)\n",
    "two_denoised_poses = np.concatenate(two_denoised_poses_list, axis=0)\n",
    "\n",
    "np.save('my_one_denoised_poses.npy', one_denoised_poses)\n",
    "np.save('my_two_denoised_poses.npy', two_denoised_poses)\n",
    "print(one_denoised_poses.shape)        \n",
    "print(two_denoised_poses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.0161279   0.17958173 -0.13632298 -0.0323379   0.35845694 -0.2802379  -0.0030379   0.48322934 -0.32446194 -0.15151297  0.28142804 -0.28007293 -0.2911984  -0.30976146 -1.340353   -0.1258459  -0.44805717 -2.7211397  -0.10238475 -0.13706458 -2.8649638   0.11382578  0.3112828  -0.17420697  0.16706531  0.13125643 -0.07483101  0.2115664  -0.02995368 -0.17348003  0.21773    -0.07914409 -0.218786   -0.06454638 -0.00565031 -0.04546189 -0.06183901 -0.22327967 -0.3589189  -0.03093021 -0.5375606  -0.29166198 -0.0168927  -0.62086636 -0.34014392  0.06206609  0.00462481 -0.0116179   0.28864872 -0.10676886 -0.21844506  0.28387338 -0.42491367 -0.09301901  0.315659   -0.50412303 -0.17950296 -0.0282913   0.31392792 -0.24269891 -0.08914915 -0.2067696  -1.9304156  -0.16959101 -0.03512414 -1.7914183   0.2366821  -0.12631857 -0.25758004  0.18226211 -0.0781848  -0.20749998]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "data = np.load('/home/vimlab/workspace/source/visualization/my_visualization/Our_ntu_denoised_skeleton_data_with_synthetic.npz')\n",
    "train = data['train']\n",
    "test = data['test']\n",
    "synthetic_test = data['synthetic_test']\n",
    "train = train.reshape(-1, 25, 3)\n",
    "test = test.reshape(-1, 25, 3)\n",
    "synthetic_test = synthetic_test.reshape(-1, 25, 3)\n",
    "#data = data.reshape(-1, 50, 3)\n",
    "\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    first_joint0 = train[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    train[i] = train[i]-first_joint0\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    first_joint0 = test[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    test[i] = test[i]-first_joint0\n",
    "\n",
    "for i in range(synthetic_test.shape[0]):\n",
    "    first_joint0 = synthetic_test[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    synthetic_test[i] = synthetic_test[i]-first_joint0\n",
    "\n",
    "train = train.reshape(-1, 75)\n",
    "test = test.reshape(-1, 75)\n",
    "synthetic_test = synthetic_test.reshape(-1, 75)\n",
    "\n",
    "print(synthetic_test[0])\n",
    "\n",
    "\n",
    "# #np.save('my_one_denoised_centered_poses.npy', data)\n",
    "#np.save('my_two_denoised_centered_poses.npy', data)\n",
    "#np.savez('my_one_denoised_synthetic_centered_poses.npz', train=train, test=test, synthetic_test=synthetic_test)\n",
    "# my_data = data[0]\n",
    "# print(my_data.shape)\n",
    "# joint0 = my_data[0]\n",
    "# joint1 = my_data[25]\n",
    "# print(joint0)\n",
    "# print(joint1)\n",
    "# #print(my_data)\n",
    "# print(my_data[:3])\n",
    "# print(my_data[25:28])\n",
    "# my_data[:25] = my_data[:25]-joint0\n",
    "# my_data[25:] = my_data[25:]-joint1\n",
    "\n",
    "# print(my_data[:3])\n",
    "# print(my_data[25:28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "la = np.load('/home/vimlab/workspace/source/visualization/my_visualization/synthetic/left_arm/synthetic_left_arm.npy')\n",
    "ra = np.load('/home/vimlab/workspace/source/visualization/my_visualization/synthetic/right_arm/synthetic_right_arm.npy')\n",
    "legs = np.load('/home/vimlab/workspace/source/visualization/my_visualization/synthetic/legs/synthetic_legs.npy')\n",
    "bodys = np.load('/home/vimlab/workspace/source/visualization/my_visualization/synthetic/body/synthetic_bodies.npy')\n",
    "\n",
    "la=la.reshape(1000, 25, 3)\n",
    "ra=ra.reshape(1000, 25, 3)\n",
    "legs=legs.reshape(1000, 25, 3)\n",
    "bodys=bodys.reshape(1000, 25, 3)\n",
    "\n",
    "for i in range(la.shape[0]):\n",
    "    first_joint0 = la[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    la[i] = la[i]-first_joint0\n",
    "\n",
    "for i in range(ra.shape[0]):\n",
    "    first_joint0 = ra[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    ra[i] = ra[i]-first_joint0\n",
    "\n",
    "for i in range(bodys.shape[0]):\n",
    "    first_joint0 = bodys[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    bodys[i] = bodys[i]-first_joint0\n",
    "\n",
    "for i in range(legs.shape[0]):\n",
    "    first_joint0 = legs[i][0]\n",
    "    #second_joint0 = data[i][25]\n",
    "    #average_joint = (first_joint0 + second_joint0)/2\n",
    "    #data[i] = data[i]-average_joint\n",
    "    legs[i] = legs[i]-first_joint0\n",
    "\n",
    "la = la.reshape(1000,75)\n",
    "ra = ra.reshape(1000,75)\n",
    "legs = legs.reshape(1000,75)\n",
    "bodys = bodys.reshape(1000,75)\n",
    "\n",
    "np.save('./synthetic/body/synthetic_centered_bodies.npy', bodys)\n",
    "np.save('./synthetic/left_arm/synthetic_centered_left_arm.npy', la)\n",
    "np.save('./synthetic/right_arm/synthetic_centered_right_arm.npy', ra)\n",
    "np.save('./synthetic/legs/synthetic_centered_legs.npy', legs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0142139  -0.2600664   0.07078004 ...  0.          0.          0.        ]\n",
      " [-0.0138849  -0.2589618   0.07446694 ...  0.          0.          0.        ]\n",
      " [-0.01410781 -0.2588182   0.07586813 ...  0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "data = np.load('/home/vimlab/workspace/source/CTR-GCN/data/ntu/NTU60_CS.npz')\n",
    "print(data['x_train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "data = np.load('/home/vimlab/workspace/source/PyTorch-Deep-SVDD_real/data/NTU/denoised_centered_poses.npy')\n",
    "\n",
    "def return_min_max(arr):\n",
    "    min = np.min(arr)\n",
    "    max = np.max(arr)\n",
    "    return min, max\n",
    "\n",
    "my_data = data[0]\n",
    "print(my_data.shape)\n",
    "#print(my_data)\n",
    "x = my_data[:,0]\n",
    "y = my_data[:,1]\n",
    "z = my_data[:,2]\n",
    "\n",
    "min_x, max_x = return_min_max(x)\n",
    "min_y, max_y = return_min_max(y)\n",
    "min_z, max_z = return_min_max(z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(data.shape[0]):\n",
    "#     x = data[i][:][0]\n",
    "#     y = data[i][:][1]\n",
    "#     z = data[i][:][2]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56578/56578 [00:00<00:00, 2797686.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4030455, 75)\n",
      "(742115, 150)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "with open('/home/vimlab/workspace/source/PyTorch-Deep-SVDD_real/data/NTU/raw_denoised_joints.pkl', 'rb') as fr:\n",
    "    raw_skes_data = pickle.load(fr)\n",
    "\n",
    "one_denoised_poses_list = []\n",
    "two_denoised_poses_list = []\n",
    "\n",
    "for (idx, body_data) in enumerate(tqdm(raw_skes_data)):\n",
    "    if body_data.shape[1]==75:\n",
    "        one_denoised_poses_list.append(body_data)\n",
    "    elif body_data.shape[1]==150:\n",
    "        two_denoised_poses_list.append(body_data)\n",
    "\n",
    "one_denoised_poses = np.concatenate(one_denoised_poses_list, axis=0)\n",
    "two_denoised_poses = np.concatenate(two_denoised_poses_list, axis=0)\n",
    "\n",
    "np.save('my_one_denoised_poses.npy', one_denoised_poses)\n",
    "np.save('my_two_denoised_poses.npy', two_denoised_poses)\n",
    "print(one_denoised_poses.shape)        \n",
    "print(two_denoised_poses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "[25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(50).reshape(1, 50)\n",
    "print(a)\n",
    "a = a.reshape(2, 25)\n",
    "\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "\n",
    "#print(a[0][:25].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "videomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
